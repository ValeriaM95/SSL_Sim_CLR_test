{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "from loss import fun_simclr_loss\n",
    "from training_function import fun_train_simclr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Hyper-parameters\n",
    "labeled_input_num  = 1000\n",
    "\n",
    "# learning rates\n",
    "learning_rate_fsp_trf   = 0.01\n",
    "learning_rate_fsp_fnt   = 0.0001\n",
    "\n",
    "learning_rate_prx_trf   = 0.01\n",
    "learning_rate_prx_fnt   = 0.000001\n",
    "\n",
    "learning_rate_dwm_trf   = 0.01\n",
    "learning_rate_dwm_fnt   = 0.0001\n",
    "\n",
    "\n",
    "# batch sizes\n",
    "batch_fsp_trf  = 128\n",
    "batch_fsp_fnt  = 128\n",
    "\n",
    "batch_prx_trf  = 64\n",
    "batch_prx_fnt  = 64\n",
    "\n",
    "batch_dwm_trf  = 128\n",
    "batch_dwm_fnt  = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_data: (50000, 32, 32, 3)\n",
      "Shape of test_data: (10000, 32, 32, 3)\n",
      "Shape of train_labels: (50000, 10)\n",
      "Shape of test_labels: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "train_data = train_data/255 # trasnform unit-8 values between 0 and 1\n",
    "test_data = test_data/255 # trasnform unit-8 values between 0 and 1\n",
    "\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "print('Shape of train_data: {}'.format(train_data.shape))\n",
    "print('Shape of test_data: {}'.format(test_data.shape))\n",
    "print('Shape of train_labels: {}'.format(train_labels.shape))\n",
    "print('Shape of test_labels: {}'.format(test_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 augmentation functions\n",
    "\n",
    "fun_augment_a  = tf.keras.layers.RandomCrop(height = 20, width = 20)\n",
    "fun_augment_b  = tf.keras.layers.Resizing(height = train_data.shape[1], \n",
    "                                          width = train_data.shape[2])\n",
    "\n",
    "fun_augment_01 = tf.keras.Sequential([fun_augment_a, fun_augment_b])\n",
    "fun_augment_02 = tf.keras.layers.RandomRotation(factor = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select labeled_data of training data\n",
    "index_tr  = tf.experimental.numpy.random.randint(0, \n",
    "                                                 train_data.shape[0], \n",
    "                                                 labeled_input_num)\n",
    "\n",
    "train_data_labeled = train_data[index_tr,:,:,:]\n",
    "train_labels_labeled = train_labels[index_tr,:]\n",
    "\n",
    "train_data_fsp = copy.deepcopy(train_data_labeled)\n",
    "train_labels_fsp = copy.deepcopy(train_labels_labeled)\n",
    "\n",
    "train_data_prx = copy.deepcopy(train_data)\n",
    "\n",
    "train_data_dwm = copy.deepcopy(train_data_labeled)\n",
    "train_labels_dwm = copy.deepcopy(train_labels_labeled)\n",
    "\n",
    "# There are 50,000 training inputs; 1000 (labeled_input_num = 1000) of them are labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model_fsp and model_dwm\n",
    "\n",
    "input_layer = tf.keras.Input(shape=(train_data.shape[1], \n",
    "                                train_data.shape[2],\n",
    "                                train_data.shape[3]))\n",
    "\n",
    "upscale = tf.keras.layers.Lambda(lambda x: tf.image.resize_with_pad(x,\n",
    "                                                                    160,\n",
    "                                                                    160,\n",
    "                                                                    method=tf.image.ResizeMethod.BILINEAR))(input_layer)\n",
    "\n",
    "model_DenseNet121 = tf.keras.applications.DenseNet121(include_top  = False,\n",
    "                                                      weights = \"imagenet\",\n",
    "                                                      input_shape = (160,160,3),\n",
    "                                                      input_tensor = upscale,\n",
    "                                                      pooling = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base_fsp =  tf.keras.models.clone_model(model_DenseNet121)\n",
    "model_base_prx =  tf.keras.models.clone_model(model_DenseNet121) # encoder\n",
    "\n",
    "model_base_fsp.set_weights(model_DenseNet121.get_weights())\n",
    "model_base_prx.set_weights(model_DenseNet121.get_weights())\n",
    "\n",
    "batch_normalization_fsp = tf.keras.layers.BatchNormalization()\n",
    "batch_normalization_prx = tf.keras.layers.BatchNormalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimCLR projector\n",
    "\n",
    "layers_dense_prx = [tf.keras.Input(shape=(1024)),\n",
    "                    tf.keras.layers.Dense(512, activation = 'relu'),\n",
    "                    tf.keras.layers.Dense(128, activation = 'relu')]\n",
    "\n",
    "model_projector = tf.keras.Sequential(layers_dense_prx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output layers of model_fsp.\n",
    "\n",
    "layerou_fsp = tf.keras.layers.Dense(train_labels_fsp.shape[-1], activation = 'softmax')\n",
    "#layerou_prx = tf.keras.layers.Dense(dataou_tr_prx.shape[-1], activation = 'softmax')\n",
    "\n",
    "model_fsp   = tf.keras.models.Sequential([model_base_fsp, \n",
    "                                          batch_normalization_fsp, \n",
    "                                          layerou_fsp])\n",
    "\n",
    "model_prx   = tf.keras.models.Sequential([model_base_prx, \n",
    "                                          batch_normalization_prx, \n",
    "                                          model_projector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet121 (Functional)    (None, 1024)              7037504   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " sequential_6 (Sequential)   (None, 128)               590464    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,632,064\n",
      "Trainable params: 590,464\n",
      "Non-trainable params: 7,041,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Train the prx model using transfer learning and fine-tuning\n",
    "# Transfer learning\n",
    "\n",
    "model_base_prx.trainable = False\n",
    "batch_normalization_prx.trainable = False\n",
    "\n",
    "model_prx.compile(optimizer = tf.keras.optimizers.Adam(learning_rate_prx_trf), \n",
    "                  loss = fun_simclr_loss, \n",
    "                  metrics = 'accuracy')\n",
    "\n",
    "model_prx.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Image Processing\\модель магистерская 2\\experiment.ipynb Ячейка 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_prx, _ \u001b[39m=\u001b[39m fun_train_simclr(model_prx, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                 train_data_prx, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                 fun_augment_01, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                 fun_augment_02, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                 epochs \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                 batch_size \u001b[39m=\u001b[39;49m batch_prx_trf, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                 verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                                 patience \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Image Processing\\модель магистерская 2\\training_function.py:39\u001b[0m, in \u001b[0;36mfun_train_simclr\u001b[1;34m(model, datain, fun_augment_01, fun_augment_02, epochs, batch_size, verbose, shuffle, patience)\u001b[0m\n\u001b[0;32m     36\u001b[0m z_real      \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform((x_tilda\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],z_size)) \u001b[39m# dummy variable\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39m# Train on batch\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m var \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_on_batch(x_tilda, z_real)\n\u001b[0;32m     40\u001b[0m loss_batch\u001b[39m.\u001b[39mappend(var[\u001b[39m0\u001b[39m]) \n\u001b[0;32m     43\u001b[0m counter  \u001b[39m=\u001b[39m counter \u001b[39m+\u001b[39m batch_size \n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\keras\\engine\\training.py:2093\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2089\u001b[0m   iterator \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39msingle_batch_iterator(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, x,\n\u001b[0;32m   2090\u001b[0m                                                 y, sample_weight,\n\u001b[0;32m   2091\u001b[0m                                                 class_weight)\n\u001b[0;32m   2092\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_train_function()\n\u001b[1;32m-> 2093\u001b[0m   logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   2095\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2096\u001b[0m \u001b[39mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\def_function.py:980\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    976\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    979\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m   _, _, _, filtered_flat_args \u001b[39m=\u001b[39m \\\n\u001b[0;32m    983\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_prx, _ = fun_train_simclr(model_prx, \n",
    "                                train_data_prx, \n",
    "                                fun_augment_01, \n",
    "                                fun_augment_02, \n",
    "                                epochs = 5, \n",
    "                                batch_size = batch_prx_trf, \n",
    "                                verbose = 1, \n",
    "                                patience = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_prx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Image Processing\\модель магистерская 2\\experiment.ipynb Ячейка 12\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model_base_prx\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m batch_normalization_prx\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model_prx\u001b[39m.\u001b[39mcompile(optimizer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate_prx_fnt), \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                   loss \u001b[39m=\u001b[39m fun_simclr_loss, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                   metrics \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model_prx, _ \u001b[39m=\u001b[39m fun_train_simclr(model_prx, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                 train_data_prx, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                                 fun_augment_01, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                                 verbose \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Image%20Processing/%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C%20%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D0%B5%D1%80%D1%81%D0%BA%D0%B0%D1%8F%202/experiment.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                                 patience \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_prx' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fine-tuning\n",
    "\n",
    "model_base_prx.trainable = True\n",
    "batch_normalization_prx.trainable = True\n",
    "\n",
    "model_prx.compile(optimizer = tf.keras.optimizers.Adam(learning_rate_prx_fnt), \n",
    "                  loss = fun_simclr_loss, \n",
    "                  metrics = 'mean_squared_error')\n",
    "\n",
    "model_prx, _ = fun_train_simclr(model_prx, \n",
    "                                train_data_prx, \n",
    "                                fun_augment_01, \n",
    "                                fun_augment_02, \n",
    "                                epochs = 1, \n",
    "                                batch_size = batch_prx_fnt, \n",
    "                                verbose = 1, \n",
    "                                patience = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also use Animal-10 kaggle dataset (take 4 classes instead of 10) => in my final model there will be 4 classes of scalp images\n",
    "# Resnet / vgg16 instead of DenseNet121 (less layers)\n",
    "# Increase the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
